{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scrapy\n",
    "import json\n",
    "from scrapy.crawler import CrawlerProcess\n",
    "from scrapy.spiders import CrawlSpider\n",
    "from scrapy.utils.project import get_project_settings\n",
    "import pandas as pd\n",
    "from pandas import DataFrame,Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scrapy import optional_features\n",
    "optional_features.remove('boto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "companies = pd.read_pickle('companies.pkl')\n",
    "companies = list(companies['name'])\n",
    "companies_l = map(lambda x:x.split(),companies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cname</th>\n",
       "      <th>post</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [cname, post, title]\n",
       "Index: []"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mn_data = DataFrame(columns=['cname','post','title'])\n",
    "mn_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(companies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "title = ''\n",
    "urls = ''\n",
    "post_text = []\n",
    "max_pages = 2\n",
    "paras = []\n",
    "class MNItem(scrapy.Item):\n",
    "    # define the fields for your item here like:\n",
    "    cname = scrapy.Field()\n",
    "    title = scrapy.Field()\n",
    "    post = scrapy.Field()\n",
    "    \n",
    "class MNSpider(CrawlSpider):\n",
    "    global max_pages\n",
    "    name = \"mnposts\"\n",
    "    allowed_domains = [\"www.medianama.com\"]\n",
    "    start_urls = []\n",
    "    for c in ['opinio','bigbasket']: #companies[100:106]:\n",
    "        for page in range(1,20):\n",
    "            start_urls.append('http://www.medianama.com/page/'+str(page)+'/?s='+c)\n",
    "    \n",
    "    def process_title(self,t):\n",
    "        exclude = set(string.punctuation)\n",
    "        t = ''.join(ch if ch not in exclude else ' ' for ch in list(t))\n",
    "        t = t.strip()\n",
    "        t = t.lower()\n",
    "        t = t.split()\n",
    "        return t\n",
    "    \n",
    "    def get_cname(self,title):\n",
    "        cname = []\n",
    "        for word in title:\n",
    "            for comp in companies_l:\n",
    "                if word in comp:\n",
    "                    cname.append(comp)\n",
    "        return cname\n",
    "        \n",
    "    \n",
    "    def getURLS(self,title):\n",
    "        url_vec = []\n",
    "        for t in title:\n",
    "            t = self.process_title(t)\n",
    "            uv = 0\n",
    "            for word in t:\n",
    "                for comp in companies_l:\n",
    "                    if word in comp:\n",
    "                        uv=1\n",
    "                        #print(t)\n",
    "            url_vec.append(uv)\n",
    "        return url_vec\n",
    "    \n",
    "    def process_paras(self,para):\n",
    "        p2 = para\n",
    "        o_index = -1\n",
    "        for i,cha in enumerate((para)):\n",
    "            if cha == '<':\n",
    "                o_index = i\n",
    "            elif cha == '>' and o_index!=-1:\n",
    "                del p2[o_index:i+1]\n",
    "                o_index = -1\n",
    "        return ''.join(p2)\n",
    "\n",
    "    def parse(self, response):\n",
    "            global title\n",
    "            global urls\n",
    "            title = response.xpath('//h3[@class=\"h2\"]/a/text()').extract()\n",
    "            title = [x.strip().encode('ascii','replace') for x in title]\n",
    "            if len(title[0])!=0:                \n",
    "                urls = response.xpath('//h3[@class=\"h2\"]/a/@href')\n",
    "                url_vec = self.getURLS(title)\n",
    "                for i in range(len(url_vec)):\n",
    "                    if url_vec[i]==1:\n",
    "                        url = urls[i].extract()\n",
    "                        yield scrapy.Request(url, callback=self.parse_dir_contents)\n",
    " \n",
    "\n",
    "\n",
    "    def parse_dir_contents(self, response):\n",
    "        global paras\n",
    "        global post_text\n",
    "        global mn_data\n",
    "        item = MNItem()\n",
    "        t = response.xpath('//h1[@class=\"entry-title single-title\"]/text()').extract()\n",
    "        #print(t)\n",
    "        it = self.process_title(t[0].encode('ascii','replace'))\n",
    "        item['title'] = it\n",
    "        item['cname'] = self.get_cname(it)\n",
    "        #print(item['cname'])\n",
    "        paras = response.xpath('//div[@class=\"entry-content clearfix\"]//p')\n",
    "        if len(paras)==0:\n",
    "            paras = response.xpath('//div[@class=\"entry-content clearfix\"]//div')\n",
    "        post_text = ' '\n",
    "        for para in paras:\n",
    "            post_text += self.process_paras(\" \".join(para.xpath('text()').extract()))\n",
    "            post_text += \" \"\n",
    "        post_text = self.process_title(post_text.encode('ascii','replace'))\n",
    "        item['post'] = post_text\n",
    "        if len(item['cname'])!=0:\n",
    "            mn_data = mn_data.append({'cname':item['cname'],'title':item['title'],'post':item['post']},\n",
    "                                      ignore_index=True)\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:scrapy.utils.log:Scrapy 1.0.5 started (bot: scrapybot)\n",
      "2016-03-26 22:35:31 [scrapy] INFO: Scrapy 1.0.5 started (bot: scrapybot)\n",
      "INFO:scrapy.utils.log:Optional features available: ssl, http11\n",
      "2016-03-26 22:35:31 [scrapy] INFO: Optional features available: ssl, http11\n",
      "INFO:scrapy.utils.log:Overridden settings: {}\n",
      "2016-03-26 22:35:31 [scrapy] INFO: Overridden settings: {}\n",
      "INFO:scrapy.middleware:Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState\n",
      "2016-03-26 22:35:31 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState\n",
      "INFO:scrapy.middleware:Enabled downloader middlewares: HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, CookiesMiddleware, ChunkedTransferMiddleware, DownloaderStats\n",
      "2016-03-26 22:35:32 [scrapy] INFO: Enabled downloader middlewares: HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, CookiesMiddleware, ChunkedTransferMiddleware, DownloaderStats\n",
      "INFO:scrapy.middleware:Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware\n",
      "2016-03-26 22:35:32 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware\n",
      "INFO:scrapy.middleware:Enabled item pipelines: \n",
      "2016-03-26 22:35:32 [scrapy] INFO: Enabled item pipelines: \n",
      "INFO:scrapy.core.engine:Spider opened\n",
      "2016-03-26 22:35:32 [scrapy] INFO: Spider opened\n",
      "INFO:scrapy.extensions.logstats:Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2016-03-26 22:35:32 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "DEBUG:scrapy.telnet:Telnet console listening on 127.0.0.1:6023\n",
      "2016-03-26 22:35:32 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023\n",
      "DEBUG:scrapy.core.engine:Crawled (200) <GET http://www.medianama.com/page/2/?s=opinio> (referer: None)\n",
      "2016-03-26 22:35:34 [scrapy] DEBUG: Crawled (200) <GET http://www.medianama.com/page/2/?s=opinio> (referer: None)\n",
      "DEBUG:scrapy.core.engine:Crawled (200) <GET http://www.medianama.com/page/7/?s=opinio> (referer: None)\n",
      "2016-03-26 22:35:35 [scrapy] DEBUG: Crawled (200) <GET http://www.medianama.com/page/7/?s=opinio> (referer: None)\n",
      "DEBUG:scrapy.core.engine:Crawled (200) <GET http://www.medianama.com/page/6/?s=opinio> (referer: None)\n",
      "2016-03-26 22:35:35 [scrapy] DEBUG: Crawled (200) <GET http://www.medianama.com/page/6/?s=opinio> (referer: None)\n",
      "DEBUG:scrapy.core.engine:Crawled (200) <GET http://www.medianama.com/page/9/?s=opinio> (referer: None)\n",
      "2016-03-26 22:35:35 [scrapy] DEBUG: Crawled (200) <GET http://www.medianama.com/page/9/?s=opinio> (referer: None)\n",
      "DEBUG:scrapy.core.engine:Crawled (200) <GET http://www.medianama.com/page/1/?s=opinio> (referer: None)\n",
      "2016-03-26 22:35:35 [scrapy] DEBUG: Crawled (200) <GET http://www.medianama.com/page/1/?s=opinio> (referer: None)\n",
      "DEBUG:scrapy.core.engine:Crawled (200) <GET http://www.medianama.com/page/4/?s=opinio> (referer: None)\n",
      "2016-03-26 22:35:36 [scrapy] DEBUG: Crawled (200) <GET http://www.medianama.com/page/4/?s=opinio> (referer: None)\n",
      "DEBUG:scrapy.core.engine:Crawled (200) <GET http://www.medianama.com/page/13/?s=opinio> (referer: None)\n",
      "2016-03-26 22:35:37 [scrapy] DEBUG: Crawled (200) <GET http://www.medianama.com/page/13/?s=opinio> (referer: None)\n",
      "DEBUG:scrapy.core.engine:Crawled (200) <GET http://www.medianama.com/page/10/?s=opinio> (referer: None)\n",
      "2016-03-26 22:35:37 [scrapy] DEBUG: Crawled (200) <GET http://www.medianama.com/page/10/?s=opinio> (referer: None)\n",
      "DEBUG:scrapy.core.engine:Crawled (200) <GET http://www.medianama.com/page/12/?s=opinio> (referer: None)\n",
      "2016-03-26 22:35:37 [scrapy] DEBUG: Crawled (200) <GET http://www.medianama.com/page/12/?s=opinio> (referer: None)\n",
      "DEBUG:scrapy.core.engine:Crawled (200) <GET http://www.medianama.com/page/14/?s=opinio> (referer: None)\n",
      "2016-03-26 22:35:37 [scrapy] DEBUG: Crawled (200) <GET http://www.medianama.com/page/14/?s=opinio> (referer: None)\n",
      "DEBUG:scrapy.core.engine:Crawled (200) <GET http://www.medianama.com/page/11/?s=opinio> (referer: None)\n",
      "2016-03-26 22:35:37 [scrapy] DEBUG: Crawled (200) <GET http://www.medianama.com/page/11/?s=opinio> (referer: None)\n",
      "DEBUG:scrapy.core.engine:Crawled (200) <GET http://www.medianama.com/page/15/?s=opinio> (referer: None)\n",
      "2016-03-26 22:35:38 [scrapy] DEBUG: Crawled (200) <GET http://www.medianama.com/page/15/?s=opinio> (referer: None)\n",
      "DEBUG:scrapy.core.engine:Crawled (200) <GET http://www.medianama.com/2015/12/223-why-has-the-trai-issued-another-net-neutrality-consultation-paper/> (referer: http://www.medianama.com/page/2/?s=opinio)\n",
      "2016-03-26 22:35:38 [scrapy] DEBUG: Crawled (200) <GET http://www.medianama.com/2015/12/223-why-has-the-trai-issued-another-net-neutrality-consultation-paper/> (referer: http://www.medianama.com/page/2/?s=opinio)\n",
      "DEBUG:scrapy.core.engine:Crawled (200) <GET http://www.medianama.com/page/16/?s=opinio> (referer: None)\n",
      "2016-03-26 22:35:38 [scrapy] DEBUG: Crawled (200) <GET http://www.medianama.com/page/16/?s=opinio> (referer: None)\n",
      "DEBUG:scrapy.core.engine:Crawled (200) <GET http://www.medianama.com/page/17/?s=opinio> (referer: None)\n",
      "2016-03-26 22:35:40 [scrapy] DEBUG: Crawled (200) <GET http://www.medianama.com/page/17/?s=opinio> (referer: None)\n",
      "DEBUG:scrapy.core.engine:Crawled (200) <GET http://www.medianama.com/2015/08/223-funding-roundup-wowexpress-pickingo-more/> (referer: http://www.medianama.com/page/1/?s=opinio)\n",
      "2016-03-26 22:35:40 [scrapy] DEBUG: Crawled (200) <GET http://www.medianama.com/2015/08/223-funding-roundup-wowexpress-pickingo-more/> (referer: http://www.medianama.com/page/1/?s=opinio)\n",
      "DEBUG:scrapy.core.engine:Crawled (200) <GET http://www.medianama.com/2015/05/223-what-mps-said-on-net-neutrality-in-the-rajya-sabha-today/> (referer: http://www.medianama.com/page/6/?s=opinio)\n",
      "2016-03-26 22:35:40 [scrapy] DEBUG: Crawled (200) <GET http://www.medianama.com/2015/05/223-what-mps-said-on-net-neutrality-in-the-rajya-sabha-today/> (referer: http://www.medianama.com/page/6/?s=opinio)\n",
      "DEBUG:scrapy.core.engine:Crawled (200) <GET http://www.medianama.com/2015/06/223-rajeev-chandrasekhar-reddit-ama/> (referer: http://www.medianama.com/page/6/?s=opinio)\n",
      "2016-03-26 22:35:41 [scrapy] DEBUG: Crawled (200) <GET http://www.medianama.com/2015/06/223-rajeev-chandrasekhar-reddit-ama/> (referer: http://www.medianama.com/page/6/?s=opinio)\n",
      "DEBUG:scrapy.core.engine:Crawled (200) <GET http://www.medianama.com/2015/10/223-opinio-funding/> (referer: http://www.medianama.com/page/1/?s=opinio)\n",
      "2016-03-26 22:35:43 [scrapy] DEBUG: Crawled (200) <GET http://www.medianama.com/2015/10/223-opinio-funding/> (referer: http://www.medianama.com/page/1/?s=opinio)\n",
      "DEBUG:scrapy.core.engine:Crawled (200) <GET http://www.medianama.com/page/5/?s=opinio> (referer: None)\n",
      "2016-03-26 22:35:43 [scrapy] DEBUG: Crawled (200) <GET http://www.medianama.com/page/5/?s=opinio> (referer: None)\n",
      "DEBUG:scrapy.core.engine:Crawled (200) <GET http://www.medianama.com/2014/02/223-99acres-magicbricks-comscore-debate/> (referer: http://www.medianama.com/page/13/?s=opinio)\n",
      "2016-03-26 22:35:44 [scrapy] DEBUG: Crawled (200) <GET http://www.medianama.com/2014/02/223-99acres-magicbricks-comscore-debate/> (referer: http://www.medianama.com/page/13/?s=opinio)\n",
      "DEBUG:scrapy.core.engine:Crawled (200) <GET http://www.medianama.com/2015/04/223-net-neutrality-misconceptions-and-misdirections/> (referer: http://www.medianama.com/page/7/?s=opinio)\n",
      "2016-03-26 22:35:44 [scrapy] DEBUG: Crawled (200) <GET http://www.medianama.com/2015/04/223-net-neutrality-misconceptions-and-misdirections/> (referer: http://www.medianama.com/page/7/?s=opinio)\n",
      "DEBUG:scrapy.core.engine:Crawled (200) <GET http://www.medianama.com/page/3/?s=opinio> (referer: None)\n",
      "2016-03-26 22:35:44 [scrapy] DEBUG: Crawled (200) <GET http://www.medianama.com/page/3/?s=opinio> (referer: None)\n",
      "DEBUG:scrapy.core.engine:Crawled (200) <GET http://www.medianama.com/2015/03/223-twitter-reliance-free-access-during-world-cup/> (referer: http://www.medianama.com/page/7/?s=opinio)\n",
      "2016-03-26 22:35:45 [scrapy] DEBUG: Crawled (200) <GET http://www.medianama.com/2015/03/223-twitter-reliance-free-access-during-world-cup/> (referer: http://www.medianama.com/page/7/?s=opinio)\n",
      "DEBUG:scrapy.core.engine:Crawled (200) <GET http://www.medianama.com/2015/05/223-coai-net-neutrality-campaign-gets-40-lakh-supporters/> (referer: http://www.medianama.com/page/7/?s=opinio)\n",
      "2016-03-26 22:35:45 [scrapy] DEBUG: Crawled (200) <GET http://www.medianama.com/2015/05/223-coai-net-neutrality-campaign-gets-40-lakh-supporters/> (referer: http://www.medianama.com/page/7/?s=opinio)\n",
      "DEBUG:scrapy.core.engine:Crawled (200) <GET http://www.medianama.com/page/8/?s=opinio> (referer: None)\n",
      "2016-03-26 22:35:45 [scrapy] DEBUG: Crawled (200) <GET http://www.medianama.com/page/8/?s=opinio> (referer: None)\n",
      "DEBUG:scrapy.core.engine:Crawled (200) <GET http://www.medianama.com/2015/12/223-rivigo-raises-30m/> (referer: http://www.medianama.com/page/2/?s=opinio)\n",
      "2016-03-26 22:35:45 [scrapy] DEBUG: Crawled (200) <GET http://www.medianama.com/2015/12/223-rivigo-raises-30m/> (referer: http://www.medianama.com/page/2/?s=opinio)\n",
      "DEBUG:scrapy.core.engine:Crawled (200) <GET http://www.medianama.com/2015/02/223-practo-co-founder-shashank-nd-on-expansion-plans-acquisitions-and-revenue-streams/> (referer: http://www.medianama.com/page/7/?s=opinio)\n",
      "2016-03-26 22:35:46 [scrapy] DEBUG: Crawled (200) <GET http://www.medianama.com/2015/02/223-practo-co-founder-shashank-nd-on-expansion-plans-acquisitions-and-revenue-streams/> (referer: http://www.medianama.com/page/7/?s=opinio)\n",
      "DEBUG:scrapy.core.engine:Crawled (200) <GET http://www.medianama.com/2015/06/223-bipin-singhs-reddit-ama-its-hard-for-mobile-banking-to-compete-with-wallets/> (referer: http://www.medianama.com/page/6/?s=opinio)\n",
      "2016-03-26 22:35:46 [scrapy] DEBUG: Crawled (200) <GET http://www.medianama.com/2015/06/223-bipin-singhs-reddit-ama-its-hard-for-mobile-banking-to-compete-with-wallets/> (referer: http://www.medianama.com/page/6/?s=opinio)\n",
      "DEBUG:scrapy.core.engine:Crawled (200) <GET http://www.medianama.com/2013/08/223-gsf-wheredowegonow-phanindra-sama-vishal-gondal/> (referer: http://www.medianama.com/page/17/?s=opinio)\n",
      "2016-03-26 22:35:46 [scrapy] DEBUG: Crawled (200) <GET http://www.medianama.com/2013/08/223-gsf-wheredowegonow-phanindra-sama-vishal-gondal/> (referer: http://www.medianama.com/page/17/?s=opinio)\n",
      "DEBUG:scrapy.core.engine:Crawled (200) <GET http://www.medianama.com/2014/01/223-why-kanwal-rekhi-didnt-want-to-exit-redbus-despite-10x-returns-startupcentral/> (referer: http://www.medianama.com/page/14/?s=opinio)\n",
      "2016-03-26 22:35:47 [scrapy] DEBUG: Crawled (200) <GET http://www.medianama.com/2014/01/223-why-kanwal-rekhi-didnt-want-to-exit-redbus-despite-10x-returns-startupcentral/> (referer: http://www.medianama.com/page/14/?s=opinio)\n",
      "DEBUG:scrapy.core.engine:Crawled (200) <GET http://www.medianama.com/page/1/?s=bigbasket> (referer: None)\n",
      "2016-03-26 22:35:47 [scrapy] DEBUG: Crawled (200) <GET http://www.medianama.com/page/1/?s=bigbasket> (referer: None)\n",
      "DEBUG:scrapy.core.engine:Crawled (200) <GET http://www.medianama.com/page/2/?s=bigbasket> (referer: None)\n",
      "2016-03-26 22:35:48 [scrapy] DEBUG: Crawled (200) <GET http://www.medianama.com/page/2/?s=bigbasket> (referer: None)\n",
      "DEBUG:scrapy.core.engine:Crawled (200) <GET http://www.medianama.com/2015/10/223-delhivery-investment-parcelled/> (referer: http://www.medianama.com/page/3/?s=opinio)\n",
      "2016-03-26 22:35:48 [scrapy] DEBUG: Crawled (200) <GET http://www.medianama.com/2015/10/223-delhivery-investment-parcelled/> (referer: http://www.medianama.com/page/3/?s=opinio)\n",
      "DEBUG:scrapy.core.engine:Crawled (200) <GET http://www.medianama.com/page/4/?s=bigbasket> (referer: None)\n",
      "2016-03-26 22:35:48 [scrapy] DEBUG: Crawled (200) <GET http://www.medianama.com/page/4/?s=bigbasket> (referer: None)\n",
      "DEBUG:scrapy.core.engine:Crawled (200) <GET http://www.medianama.com/page/3/?s=bigbasket> (referer: None)\n",
      "2016-03-26 22:35:49 [scrapy] DEBUG: Crawled (200) <GET http://www.medianama.com/page/3/?s=bigbasket> (referer: None)\n",
      "DEBUG:scrapy.core.engine:Crawled (200) <GET http://www.medianama.com/page/5/?s=bigbasket> (referer: None)\n",
      "2016-03-26 22:35:49 [scrapy] DEBUG: Crawled (200) <GET http://www.medianama.com/page/5/?s=bigbasket> (referer: None)\n",
      "DEBUG:scrapy.core.engine:Crawled (404) <GET http://www.medianama.com/page/8/?s=bigbasket> (referer: None)\n",
      "2016-03-26 22:35:50 [scrapy] DEBUG: Crawled (404) <GET http://www.medianama.com/page/8/?s=bigbasket> (referer: None)\n",
      "DEBUG:scrapy.core.engine:Crawled (404) <GET http://www.medianama.com/page/6/?s=bigbasket> (referer: None)\n",
      "2016-03-26 22:35:50 [scrapy] DEBUG: Crawled (404) <GET http://www.medianama.com/page/6/?s=bigbasket> (referer: None)\n",
      "DEBUG:scrapy.spidermiddlewares.httperror:Ignoring response <404 http://www.medianama.com/page/8/?s=bigbasket>: HTTP status code is not handled or not allowed\n",
      "2016-03-26 22:35:50 [scrapy] DEBUG: Ignoring response <404 http://www.medianama.com/page/8/?s=bigbasket>: HTTP status code is not handled or not allowed\n",
      "DEBUG:scrapy.spidermiddlewares.httperror:Ignoring response <404 http://www.medianama.com/page/6/?s=bigbasket>: HTTP status code is not handled or not allowed\n",
      "2016-03-26 22:35:50 [scrapy] DEBUG: Ignoring response <404 http://www.medianama.com/page/6/?s=bigbasket>: HTTP status code is not handled or not allowed\n",
      "DEBUG:scrapy.core.engine:Crawled (200) <GET http://www.medianama.com/2015/01/223-how-indian-telecom-operators-defend-their-attack-on-net-neutrality/> (referer: http://www.medianama.com/page/8/?s=opinio)\n",
      "2016-03-26 22:35:50 [scrapy] DEBUG: Crawled (200) <GET http://www.medianama.com/2015/01/223-how-indian-telecom-operators-defend-their-attack-on-net-neutrality/> (referer: http://www.medianama.com/page/8/?s=opinio)\n",
      "DEBUG:scrapy.core.engine:Crawled (404) <GET http://www.medianama.com/page/9/?s=bigbasket> (referer: None)\n",
      "2016-03-26 22:35:52 [scrapy] DEBUG: Crawled (404) <GET http://www.medianama.com/page/9/?s=bigbasket> (referer: None)\n",
      "DEBUG:scrapy.spidermiddlewares.httperror:Ignoring response <404 http://www.medianama.com/page/9/?s=bigbasket>: HTTP status code is not handled or not allowed\n",
      "2016-03-26 22:35:52 [scrapy] DEBUG: Ignoring response <404 http://www.medianama.com/page/9/?s=bigbasket>: HTTP status code is not handled or not allowed\n",
      "DEBUG:scrapy.core.engine:Crawled (404) <GET http://www.medianama.com/page/11/?s=bigbasket> (referer: None)\n",
      "2016-03-26 22:35:52 [scrapy] DEBUG: Crawled (404) <GET http://www.medianama.com/page/11/?s=bigbasket> (referer: None)\n",
      "DEBUG:scrapy.spidermiddlewares.httperror:Ignoring response <404 http://www.medianama.com/page/11/?s=bigbasket>: HTTP status code is not handled or not allowed\n",
      "2016-03-26 22:35:52 [scrapy] DEBUG: Ignoring response <404 http://www.medianama.com/page/11/?s=bigbasket>: HTTP status code is not handled or not allowed\n",
      "DEBUG:scrapy.core.engine:Crawled (404) <GET http://www.medianama.com/page/10/?s=bigbasket> (referer: None)\n",
      "2016-03-26 22:35:52 [scrapy] DEBUG: Crawled (404) <GET http://www.medianama.com/page/10/?s=bigbasket> (referer: None)\n",
      "DEBUG:scrapy.spidermiddlewares.httperror:Ignoring response <404 http://www.medianama.com/page/10/?s=bigbasket>: HTTP status code is not handled or not allowed\n",
      "2016-03-26 22:35:52 [scrapy] DEBUG: Ignoring response <404 http://www.medianama.com/page/10/?s=bigbasket>: HTTP status code is not handled or not allowed\n",
      "DEBUG:scrapy.core.engine:Crawled (200) <GET http://www.medianama.com/2015/04/223-net-neutrality-telcos-are-not-losing-money-to-data-services-deepak-shenoy/> (referer: http://www.medianama.com/page/7/?s=opinio)\n",
      "2016-03-26 22:35:52 [scrapy] DEBUG: Crawled (200) <GET http://www.medianama.com/2015/04/223-net-neutrality-telcos-are-not-losing-money-to-data-services-deepak-shenoy/> (referer: http://www.medianama.com/page/7/?s=opinio)\n",
      "DEBUG:scrapy.core.engine:Crawled (200) <GET http://www.medianama.com/page/19/?s=opinio> (referer: None)\n",
      "2016-03-26 22:35:53 [scrapy] DEBUG: Crawled (200) <GET http://www.medianama.com/page/19/?s=opinio> (referer: None)\n",
      "DEBUG:scrapy.core.engine:Crawled (200) <GET http://www.medianama.com/2014/08/223-meena-k-ganesh-srikanth-iyer-launch-online-furniture-marketplace-homelane/> (referer: http://www.medianama.com/page/4/?s=bigbasket)\n",
      "2016-03-26 22:35:53 [scrapy] DEBUG: Crawled (200) <GET http://www.medianama.com/2014/08/223-meena-k-ganesh-srikanth-iyer-launch-online-furniture-marketplace-homelane/> (referer: http://www.medianama.com/page/4/?s=bigbasket)\n",
      "DEBUG:scrapy.core.engine:Crawled (404) <GET http://www.medianama.com/page/7/?s=bigbasket> (referer: None)\n",
      "2016-03-26 22:35:53 [scrapy] DEBUG: Crawled (404) <GET http://www.medianama.com/page/7/?s=bigbasket> (referer: None)\n",
      "DEBUG:scrapy.spidermiddlewares.httperror:Ignoring response <404 http://www.medianama.com/page/7/?s=bigbasket>: HTTP status code is not handled or not allowed\n",
      "2016-03-26 22:35:53 [scrapy] DEBUG: Ignoring response <404 http://www.medianama.com/page/7/?s=bigbasket>: HTTP status code is not handled or not allowed\n",
      "DEBUG:scrapy.core.engine:Crawled (200) <GET http://www.medianama.com/page/18/?s=opinio> (referer: None)\n",
      "2016-03-26 22:35:53 [scrapy] DEBUG: Crawled (200) <GET http://www.medianama.com/page/18/?s=opinio> (referer: None)\n",
      "DEBUG:scrapy.core.engine:Crawled (200) <GET http://www.medianama.com/2013/07/223-jabong-myntra-yebhi-using-transaction-sms-pipe-for-promotion-ussd-spam-via-airtel/> (referer: http://www.medianama.com/page/17/?s=opinio)\n",
      "2016-03-26 22:35:55 [scrapy] DEBUG: Crawled (200) <GET http://www.medianama.com/2013/07/223-jabong-myntra-yebhi-using-transaction-sms-pipe-for-promotion-ussd-spam-via-airtel/> (referer: http://www.medianama.com/page/17/?s=opinio)\n",
      "DEBUG:scrapy.core.engine:Crawled (200) <GET http://www.medianama.com/2014/11/223-e-commerce-roundup-amazon-jabong-flipkart-bigbasket-more/> (referer: http://www.medianama.com/page/1/?s=bigbasket)\n",
      "2016-03-26 22:35:57 [scrapy] DEBUG: Crawled (200) <GET http://www.medianama.com/2014/11/223-e-commerce-roundup-amazon-jabong-flipkart-bigbasket-more/> (referer: http://www.medianama.com/page/1/?s=bigbasket)\n",
      "DEBUG:scrapy.core.engine:Crawled (404) <GET http://www.medianama.com/page/16/?s=bigbasket> (referer: None)\n",
      "2016-03-26 22:35:58 [scrapy] DEBUG: Crawled (404) <GET http://www.medianama.com/page/16/?s=bigbasket> (referer: None)\n",
      "DEBUG:scrapy.spidermiddlewares.httperror:Ignoring response <404 http://www.medianama.com/page/16/?s=bigbasket>: HTTP status code is not handled or not allowed\n",
      "2016-03-26 22:35:58 [scrapy] DEBUG: Ignoring response <404 http://www.medianama.com/page/16/?s=bigbasket>: HTTP status code is not handled or not allowed\n",
      "DEBUG:scrapy.core.engine:Crawled (404) <GET http://www.medianama.com/page/15/?s=bigbasket> (referer: None)\n",
      "2016-03-26 22:35:58 [scrapy] DEBUG: Crawled (404) <GET http://www.medianama.com/page/15/?s=bigbasket> (referer: None)\n",
      "DEBUG:scrapy.spidermiddlewares.httperror:Ignoring response <404 http://www.medianama.com/page/15/?s=bigbasket>: HTTP status code is not handled or not allowed\n",
      "2016-03-26 22:35:58 [scrapy] DEBUG: Ignoring response <404 http://www.medianama.com/page/15/?s=bigbasket>: HTTP status code is not handled or not allowed\n",
      "DEBUG:scrapy.core.engine:Crawled (404) <GET http://www.medianama.com/page/13/?s=bigbasket> (referer: None)\n",
      "2016-03-26 22:35:58 [scrapy] DEBUG: Crawled (404) <GET http://www.medianama.com/page/13/?s=bigbasket> (referer: None)\n",
      "DEBUG:scrapy.spidermiddlewares.httperror:Ignoring response <404 http://www.medianama.com/page/13/?s=bigbasket>: HTTP status code is not handled or not allowed\n",
      "2016-03-26 22:35:58 [scrapy] DEBUG: Ignoring response <404 http://www.medianama.com/page/13/?s=bigbasket>: HTTP status code is not handled or not allowed\n",
      "DEBUG:scrapy.core.engine:Crawled (404) <GET http://www.medianama.com/page/17/?s=bigbasket> (referer: None)\n",
      "2016-03-26 22:35:59 [scrapy] DEBUG: Crawled (404) <GET http://www.medianama.com/page/17/?s=bigbasket> (referer: None)\n",
      "DEBUG:scrapy.spidermiddlewares.httperror:Ignoring response <404 http://www.medianama.com/page/17/?s=bigbasket>: HTTP status code is not handled or not allowed\n",
      "2016-03-26 22:35:59 [scrapy] DEBUG: Ignoring response <404 http://www.medianama.com/page/17/?s=bigbasket>: HTTP status code is not handled or not allowed\n",
      "DEBUG:scrapy.core.engine:Crawled (200) <GET http://www.medianama.com/2015/01/223-e-commerce-roundup-natures-basket-snapdeal-flipkart-and-jabong/> (referer: http://www.medianama.com/page/3/?s=bigbasket)\n",
      "2016-03-26 22:36:03 [scrapy] DEBUG: Crawled (200) <GET http://www.medianama.com/2015/01/223-e-commerce-roundup-natures-basket-snapdeal-flipkart-and-jabong/> (referer: http://www.medianama.com/page/3/?s=bigbasket)\n",
      "DEBUG:scrapy.core.engine:Crawled (404) <GET http://www.medianama.com/page/12/?s=bigbasket> (referer: None)\n",
      "2016-03-26 22:36:03 [scrapy] DEBUG: Crawled (404) <GET http://www.medianama.com/page/12/?s=bigbasket> (referer: None)\n",
      "DEBUG:scrapy.spidermiddlewares.httperror:Ignoring response <404 http://www.medianama.com/page/12/?s=bigbasket>: HTTP status code is not handled or not allowed\n",
      "2016-03-26 22:36:03 [scrapy] DEBUG: Ignoring response <404 http://www.medianama.com/page/12/?s=bigbasket>: HTTP status code is not handled or not allowed\n",
      "DEBUG:scrapy.core.engine:Crawled (404) <GET http://www.medianama.com/page/18/?s=bigbasket> (referer: None)\n",
      "2016-03-26 22:36:03 [scrapy] DEBUG: Crawled (404) <GET http://www.medianama.com/page/18/?s=bigbasket> (referer: None)\n",
      "DEBUG:scrapy.spidermiddlewares.httperror:Ignoring response <404 http://www.medianama.com/page/18/?s=bigbasket>: HTTP status code is not handled or not allowed\n",
      "2016-03-26 22:36:03 [scrapy] DEBUG: Ignoring response <404 http://www.medianama.com/page/18/?s=bigbasket>: HTTP status code is not handled or not allowed\n",
      "DEBUG:scrapy.core.engine:Crawled (404) <GET http://www.medianama.com/page/14/?s=bigbasket> (referer: None)\n",
      "2016-03-26 22:36:03 [scrapy] DEBUG: Crawled (404) <GET http://www.medianama.com/page/14/?s=bigbasket> (referer: None)\n",
      "DEBUG:scrapy.spidermiddlewares.httperror:Ignoring response <404 http://www.medianama.com/page/14/?s=bigbasket>: HTTP status code is not handled or not allowed\n",
      "2016-03-26 22:36:04 [scrapy] DEBUG: Ignoring response <404 http://www.medianama.com/page/14/?s=bigbasket>: HTTP status code is not handled or not allowed\n",
      "DEBUG:scrapy.core.engine:Crawled (404) <GET http://www.medianama.com/page/19/?s=bigbasket> (referer: None)\n",
      "2016-03-26 22:36:04 [scrapy] DEBUG: Crawled (404) <GET http://www.medianama.com/page/19/?s=bigbasket> (referer: None)\n",
      "DEBUG:scrapy.spidermiddlewares.httperror:Ignoring response <404 http://www.medianama.com/page/19/?s=bigbasket>: HTTP status code is not handled or not allowed\n",
      "2016-03-26 22:36:04 [scrapy] DEBUG: Ignoring response <404 http://www.medianama.com/page/19/?s=bigbasket>: HTTP status code is not handled or not allowed\n",
      "INFO:scrapy.core.engine:Closing spider (finished)\n",
      "2016-03-26 22:36:04 [scrapy] INFO: Closing spider (finished)\n",
      "INFO:scrapy.statscollectors:Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 20209,\n",
      " 'downloader/request_count': 59,\n",
      " 'downloader/request_method_count/GET': 59,\n",
      " 'downloader/response_bytes': 1092657,\n",
      " 'downloader/response_count': 59,\n",
      " 'downloader/response_status_count/200': 45,\n",
      " 'downloader/response_status_count/404': 14,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2016, 3, 26, 17, 6, 4, 128000),\n",
      " 'log_count/DEBUG': 74,\n",
      " 'log_count/INFO': 7,\n",
      " 'request_depth_max': 1,\n",
      " 'response_received_count': 59,\n",
      " 'scheduler/dequeued': 59,\n",
      " 'scheduler/dequeued/memory': 59,\n",
      " 'scheduler/enqueued': 59,\n",
      " 'scheduler/enqueued/memory': 59,\n",
      " 'start_time': datetime.datetime(2016, 3, 26, 17, 5, 32, 108000)}\n",
      "2016-03-26 22:36:04 [scrapy] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 20209,\n",
      " 'downloader/request_count': 59,\n",
      " 'downloader/request_method_count/GET': 59,\n",
      " 'downloader/response_bytes': 1092657,\n",
      " 'downloader/response_count': 59,\n",
      " 'downloader/response_status_count/200': 45,\n",
      " 'downloader/response_status_count/404': 14,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2016, 3, 26, 17, 6, 4, 128000),\n",
      " 'log_count/DEBUG': 74,\n",
      " 'log_count/INFO': 7,\n",
      " 'request_depth_max': 1,\n",
      " 'response_received_count': 59,\n",
      " 'scheduler/dequeued': 59,\n",
      " 'scheduler/dequeued/memory': 59,\n",
      " 'scheduler/enqueued': 59,\n",
      " 'scheduler/enqueued/memory': 59,\n",
      " 'start_time': datetime.datetime(2016, 3, 26, 17, 5, 32, 108000)}\n",
      "INFO:scrapy.core.engine:Spider closed (finished)\n",
      "2016-03-26 22:36:04 [scrapy] INFO: Spider closed (finished)\n"
     ]
    }
   ],
   "source": [
    "process = CrawlerProcess(get_project_settings())\n",
    "process.crawl(MNSpider)\n",
    "process.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mn_data = mn_data.append(pd.read_pickle('mn_note.pkl'),ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mn_data.to_pickle('mn_note.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cname</th>\n",
       "      <th>post</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[indusnet, indus, net]]</td>\n",
       "      <td>[in, an, unexpected, and, frankly, inexplicabl...</td>\n",
       "      <td>[why, has, the, trai, issued, another, net, ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[pickingo]]</td>\n",
       "      <td>[mumbai, based, logistics, solutions, company,...</td>\n",
       "      <td>[funding, roundup, wow, express, opinio, picki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[indusnet, indus, net]]</td>\n",
       "      <td>[there, was, a, discussion, on, net, neutralit...</td>\n",
       "      <td>[what, mps, said, on, net, neutrality, in, the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[indusnet, indus, net]]</td>\n",
       "      <td>[an, independent, member, of, parliament, in, ...</td>\n",
       "      <td>[rajeev, chandrasekhar, on, reddit, ama, trai,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[delhivery]]</td>\n",
       "      <td>[bangalore, based, hyperlocal, delivery, start...</td>\n",
       "      <td>[opinio, secures, 7m, from, delhivery, sands, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[[magicbricks]]</td>\n",
       "      <td>[following, our, story, on, magicbricks, head,...</td>\n",
       "      <td>[magicbricks, calls, out, 99acres, on, its, no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[[indusnet, indus, net]]</td>\n",
       "      <td>[the, issue, of, network, neutrality, has, rea...</td>\n",
       "      <td>[net, neutrality, misconceptions, and, misdire...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[[indusnet, indus, net]]</td>\n",
       "      <td>[twitter, is, offering, reliance, subscribers,...</td>\n",
       "      <td>[twitter, offering, reliance, subscribers, fre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[[indusnet, indus, net]]</td>\n",
       "      <td>[telecom, lobby, group, coai, has, said, it, h...</td>\n",
       "      <td>[coai, s, net, neutrality, campaign, gets, 40,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[[rivigo]]</td>\n",
       "      <td>[gurgaon, based, logistics, services, provider...</td>\n",
       "      <td>[rivigo, raises, 30m, from, saif, partners, ot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[[practo]]</td>\n",
       "      <td>[healthcare, technology, company, announced, l...</td>\n",
       "      <td>[practo, co, founder, shashank, nd, on, expans...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[[mobikwik]]</td>\n",
       "      <td>[founder, ceo, of, mobile, wallet, firm, mobik...</td>\n",
       "      <td>[mobikwik, ceo, bipin, singh, s, reddit, ama, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[[redbus]]</td>\n",
       "      <td>[at, gsf, s, conference, redbus, co, founder, ...</td>\n",
       "      <td>[gsf, wheredowegonow, phanindra, sama, on, eso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[[redbus]]</td>\n",
       "      <td>[online, bus, ticketing, company, may, have, d...</td>\n",
       "      <td>[why, kanwal, rekhi, didn, t, want, to, exit, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[[parcelled], [delhivery]]</td>\n",
       "      <td>[bangalore, based, shipping, services, startup...</td>\n",
       "      <td>[parcelled, secures, 5m, from, delhivery, trac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[[indusnet, indus, net]]</td>\n",
       "      <td>[the, cellular, operators, association, of, in...</td>\n",
       "      <td>[how, indian, telecom, operators, defend, thei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[[indusnet, indus, net]]</td>\n",
       "      <td>[the, arguments, by, telecom, operators, again...</td>\n",
       "      <td>[net, neutrality, telcos, are, not, losing, mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[[homelane]]</td>\n",
       "      <td>[k, ganesh, and, meena, have, acquired, bangal...</td>\n",
       "      <td>[meena, k, ganesh, srikanth, iyer, launch, onl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[[jabong]]</td>\n",
       "      <td>[india, s, telecom, regulator, trai, needs, to...</td>\n",
       "      <td>[jabong, myntra, yebhi, using, transaction, sm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[[jabong]]</td>\n",
       "      <td>[has, launched, its, kannada, books, movies, a...</td>\n",
       "      <td>[e, commerce, roundup, amazon, jabong, flipkar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[[jabong]]</td>\n",
       "      <td>[has, tied, up, with, snapdeal, com, to, make,...</td>\n",
       "      <td>[e, commerce, roundup, nature, s, basket, snap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[[vserv]]</td>\n",
       "      <td>[mobile, marketing, platform, has, tied, up, w...</td>\n",
       "      <td>[vserv, partners, xl, to, enable, customer, ta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[[vserv]]</td>\n",
       "      <td>[has, appointed, as, its, vice, president, glo...</td>\n",
       "      <td>[vserv, ropes, in, shailesh, varudkar, as, vp,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[[vserv]]</td>\n",
       "      <td>[mobile, ad, network, has, launched, its, appw...</td>\n",
       "      <td>[vserv, launches, appwrapper, platform]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[[vserv]]</td>\n",
       "      <td>[company, founded, by, two, mauj, mobile, exec...</td>\n",
       "      <td>[vserv, launches, wap, java, apps, ad, network...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>[[inmobi]]</td>\n",
       "      <td>[mobile, ad, network, has, launched, a, native...</td>\n",
       "      <td>[inmobi, debuts, native, ads, platform]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>[[vserv]]</td>\n",
       "      <td>[internet, advertising, company, online, media...</td>\n",
       "      <td>[industry, moves, omg, vserv, mindshare, port,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>[[vserv]]</td>\n",
       "      <td>[a, mobile, ad, network, that, offers, mobile,...</td>\n",
       "      <td>[industry, moves, vserv, mobi, network18]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>[[inmobi]]</td>\n",
       "      <td>[this, has, a, prodigal, son, returns, feel, t...</td>\n",
       "      <td>[inmobi, focus, back, on, india, plans, appoin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>[[fractal, analytics]]</td>\n",
       "      <td>[a, mobile, media, distribution, and, analytic...</td>\n",
       "      <td>[seventynine, launches, mobile, app, analytics...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1739</th>\n",
       "      <td>[[indusnet, indus, net]]</td>\n",
       "      <td>[another, quarter, goes, by, and, television, ...</td>\n",
       "      <td>[tv18, net, losses, at, rs, 415m, rs, 45m, was...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1740</th>\n",
       "      <td>[[burrp]]</td>\n",
       "      <td>[network18s, internet, company, web18, is, pla...</td>\n",
       "      <td>[web18, roundup, burrp, indrive, im, launch, u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1741</th>\n",
       "      <td>[[indusnet, indus, net]]</td>\n",
       "      <td>[tv18, s, net, losses, more, than, quadrupled,...</td>\n",
       "      <td>[q1, 10, tv18, net, loss, soars, to, rs, 406, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1742</th>\n",
       "      <td>[[freecharge]]</td>\n",
       "      <td>[deep, ubhi, founder, of, local, search, site,...</td>\n",
       "      <td>[industry, moves, freecharge, in, possible, wo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1743</th>\n",
       "      <td>[[indusnet, indus, net]]</td>\n",
       "      <td>[which, owns, various, publications, such, as,...</td>\n",
       "      <td>[updated, q409, results, infomedia18, qoq, net...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1744</th>\n",
       "      <td>[[burrp]]</td>\n",
       "      <td>[an, update, on, infomedia18s, acquisition, of...</td>\n",
       "      <td>[infomedia18, had, acquired, burrp, for, rs, 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1745</th>\n",
       "      <td>[[saavn]]</td>\n",
       "      <td>[obliging, with, regulatory, requirements, loo...</td>\n",
       "      <td>[round, up, loop, goes, to, tn, orissa, saavn,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1746</th>\n",
       "      <td>[[indusnet, indus, net]]</td>\n",
       "      <td>[has, made, a, turnaround, posting, an, operat...</td>\n",
       "      <td>[network18, net, loss, down, 74, setpro, rev, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1747</th>\n",
       "      <td>[[burrp]]</td>\n",
       "      <td>[the, weekend, witnessed, a, spat, between, po...</td>\n",
       "      <td>[zomato, accuses, burrp, of, copying, listings...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1748</th>\n",
       "      <td>[[burrp]]</td>\n",
       "      <td>[just, dial, is, said, to, have, closed, a, de...</td>\n",
       "      <td>[news, digest, just, dial, bharti, olive, tele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1749</th>\n",
       "      <td>[[burrp]]</td>\n",
       "      <td>[network18, s, news, and, views, website, firs...</td>\n",
       "      <td>[app, round, up, firstpost, getit, burrp, cond...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1750</th>\n",
       "      <td>[[burrp], [burrp]]</td>\n",
       "      <td>[infomedia18, owned, restaurant, guide, burrp,...</td>\n",
       "      <td>[burrp, launches, restaurant, discovery, tool,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1751</th>\n",
       "      <td>[[burrp]]</td>\n",
       "      <td>[online, restaurant, and, events, guide, has, ...</td>\n",
       "      <td>[burrp, launches, iphone, app, review]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1752</th>\n",
       "      <td>[[nowfloats]]</td>\n",
       "      <td>[nowfloats, is, a, location, based, mobile, se...</td>\n",
       "      <td>[nowfloats, offers, location, based, contextua...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1753</th>\n",
       "      <td>[[burrp]]</td>\n",
       "      <td>[updated, with, some, corrections, recently, m...</td>\n",
       "      <td>[updated, indian, apps, for, windows, 8, cp, i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1754</th>\n",
       "      <td>[[burrp]]</td>\n",
       "      <td>[online, restaurants, and, events, guide, has,...</td>\n",
       "      <td>[burrp, launches, invite, only, loyalty, club,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1755</th>\n",
       "      <td>[[burrp]]</td>\n",
       "      <td>[sandeep, das, has, joined, s, senior, managem...</td>\n",
       "      <td>[antfarm, plans, to, enter, fitness, classifie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1756</th>\n",
       "      <td>[[burrp]]</td>\n",
       "      <td>[speaking, with, medianama, vishal, anand, bur...</td>\n",
       "      <td>[just, let, s, get, back, to, business, it, s,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1757</th>\n",
       "      <td>[[burrp]]</td>\n",
       "      <td>[after, we, published, on, the, round, of, all...</td>\n",
       "      <td>[we, have, decided, not, to, take, any, legal,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1758</th>\n",
       "      <td>[[freecharge]]</td>\n",
       "      <td>[e, commerce, marketplace, snapdeal, is, in, l...</td>\n",
       "      <td>[why, snapdeal, wants, to, buy, freecharge]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1759</th>\n",
       "      <td>[[native5]]</td>\n",
       "      <td>[online, fashion, store, myntra, has, acquired...</td>\n",
       "      <td>[myntra, acquires, mobile, app, development, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1760</th>\n",
       "      <td>[[adiquity]]</td>\n",
       "      <td>[s, mobile, ads, mediation, and, optimization,...</td>\n",
       "      <td>[guruji, com, s, adiquity, launches, ad, excha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1761</th>\n",
       "      <td>[[komli]]</td>\n",
       "      <td>[online, ad, network, has, launched, a, real, ...</td>\n",
       "      <td>[komli, launches, real, time, bidding, based, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1762</th>\n",
       "      <td>[[fractal, analytics]]</td>\n",
       "      <td>[a, mobile, media, distribution, and, analytic...</td>\n",
       "      <td>[seventynine, launches, mobile, app, analytics...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1763</th>\n",
       "      <td>[[adiquity]]</td>\n",
       "      <td>[a, mobile, advertising, platform, based, in, ...</td>\n",
       "      <td>[mobile, ad, network, adiquity, partners, with...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1764</th>\n",
       "      <td>[[adiquity]]</td>\n",
       "      <td>[mauj, people, infocomm, owned, mobile, applic...</td>\n",
       "      <td>[mobango, integrates, guruji, com, s, adiquity...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1765</th>\n",
       "      <td>[[adiquity], [appiterate]]</td>\n",
       "      <td>[ecommerce, giant, has, acquired, the, mobile,...</td>\n",
       "      <td>[after, adiquity, flipkart, acquires, mobile, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1766</th>\n",
       "      <td>[[adiquity]]</td>\n",
       "      <td>[update, flipkart, has, confirmed, the, acquis...</td>\n",
       "      <td>[updated, flipkart, buys, out, mobile, ad, fir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1767</th>\n",
       "      <td>[[adiquity], [appiterate]]</td>\n",
       "      <td>[anurag, dod, tanuj, mendiratta]</td>\n",
       "      <td>[ceos, of, acquired, cos, adiquity, and, appit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1768</th>\n",
       "      <td>[[adiquity]]</td>\n",
       "      <td>[after, recently, its, music, search, engine, ...</td>\n",
       "      <td>[guruji, com, launches, mobile, ads, optimizat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1769 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           cname  \\\n",
       "0       [[indusnet, indus, net]]   \n",
       "1                   [[pickingo]]   \n",
       "2       [[indusnet, indus, net]]   \n",
       "3       [[indusnet, indus, net]]   \n",
       "4                  [[delhivery]]   \n",
       "5                [[magicbricks]]   \n",
       "6       [[indusnet, indus, net]]   \n",
       "7       [[indusnet, indus, net]]   \n",
       "8       [[indusnet, indus, net]]   \n",
       "9                     [[rivigo]]   \n",
       "10                    [[practo]]   \n",
       "11                  [[mobikwik]]   \n",
       "12                    [[redbus]]   \n",
       "13                    [[redbus]]   \n",
       "14    [[parcelled], [delhivery]]   \n",
       "15      [[indusnet, indus, net]]   \n",
       "16      [[indusnet, indus, net]]   \n",
       "17                  [[homelane]]   \n",
       "18                    [[jabong]]   \n",
       "19                    [[jabong]]   \n",
       "20                    [[jabong]]   \n",
       "21                     [[vserv]]   \n",
       "22                     [[vserv]]   \n",
       "23                     [[vserv]]   \n",
       "24                     [[vserv]]   \n",
       "25                    [[inmobi]]   \n",
       "26                     [[vserv]]   \n",
       "27                     [[vserv]]   \n",
       "28                    [[inmobi]]   \n",
       "29        [[fractal, analytics]]   \n",
       "...                          ...   \n",
       "1739    [[indusnet, indus, net]]   \n",
       "1740                   [[burrp]]   \n",
       "1741    [[indusnet, indus, net]]   \n",
       "1742              [[freecharge]]   \n",
       "1743    [[indusnet, indus, net]]   \n",
       "1744                   [[burrp]]   \n",
       "1745                   [[saavn]]   \n",
       "1746    [[indusnet, indus, net]]   \n",
       "1747                   [[burrp]]   \n",
       "1748                   [[burrp]]   \n",
       "1749                   [[burrp]]   \n",
       "1750          [[burrp], [burrp]]   \n",
       "1751                   [[burrp]]   \n",
       "1752               [[nowfloats]]   \n",
       "1753                   [[burrp]]   \n",
       "1754                   [[burrp]]   \n",
       "1755                   [[burrp]]   \n",
       "1756                   [[burrp]]   \n",
       "1757                   [[burrp]]   \n",
       "1758              [[freecharge]]   \n",
       "1759                 [[native5]]   \n",
       "1760                [[adiquity]]   \n",
       "1761                   [[komli]]   \n",
       "1762      [[fractal, analytics]]   \n",
       "1763                [[adiquity]]   \n",
       "1764                [[adiquity]]   \n",
       "1765  [[adiquity], [appiterate]]   \n",
       "1766                [[adiquity]]   \n",
       "1767  [[adiquity], [appiterate]]   \n",
       "1768                [[adiquity]]   \n",
       "\n",
       "                                                   post  \\\n",
       "0     [in, an, unexpected, and, frankly, inexplicabl...   \n",
       "1     [mumbai, based, logistics, solutions, company,...   \n",
       "2     [there, was, a, discussion, on, net, neutralit...   \n",
       "3     [an, independent, member, of, parliament, in, ...   \n",
       "4     [bangalore, based, hyperlocal, delivery, start...   \n",
       "5     [following, our, story, on, magicbricks, head,...   \n",
       "6     [the, issue, of, network, neutrality, has, rea...   \n",
       "7     [twitter, is, offering, reliance, subscribers,...   \n",
       "8     [telecom, lobby, group, coai, has, said, it, h...   \n",
       "9     [gurgaon, based, logistics, services, provider...   \n",
       "10    [healthcare, technology, company, announced, l...   \n",
       "11    [founder, ceo, of, mobile, wallet, firm, mobik...   \n",
       "12    [at, gsf, s, conference, redbus, co, founder, ...   \n",
       "13    [online, bus, ticketing, company, may, have, d...   \n",
       "14    [bangalore, based, shipping, services, startup...   \n",
       "15    [the, cellular, operators, association, of, in...   \n",
       "16    [the, arguments, by, telecom, operators, again...   \n",
       "17    [k, ganesh, and, meena, have, acquired, bangal...   \n",
       "18    [india, s, telecom, regulator, trai, needs, to...   \n",
       "19    [has, launched, its, kannada, books, movies, a...   \n",
       "20    [has, tied, up, with, snapdeal, com, to, make,...   \n",
       "21    [mobile, marketing, platform, has, tied, up, w...   \n",
       "22    [has, appointed, as, its, vice, president, glo...   \n",
       "23    [mobile, ad, network, has, launched, its, appw...   \n",
       "24    [company, founded, by, two, mauj, mobile, exec...   \n",
       "25    [mobile, ad, network, has, launched, a, native...   \n",
       "26    [internet, advertising, company, online, media...   \n",
       "27    [a, mobile, ad, network, that, offers, mobile,...   \n",
       "28    [this, has, a, prodigal, son, returns, feel, t...   \n",
       "29    [a, mobile, media, distribution, and, analytic...   \n",
       "...                                                 ...   \n",
       "1739  [another, quarter, goes, by, and, television, ...   \n",
       "1740  [network18s, internet, company, web18, is, pla...   \n",
       "1741  [tv18, s, net, losses, more, than, quadrupled,...   \n",
       "1742  [deep, ubhi, founder, of, local, search, site,...   \n",
       "1743  [which, owns, various, publications, such, as,...   \n",
       "1744  [an, update, on, infomedia18s, acquisition, of...   \n",
       "1745  [obliging, with, regulatory, requirements, loo...   \n",
       "1746  [has, made, a, turnaround, posting, an, operat...   \n",
       "1747  [the, weekend, witnessed, a, spat, between, po...   \n",
       "1748  [just, dial, is, said, to, have, closed, a, de...   \n",
       "1749  [network18, s, news, and, views, website, firs...   \n",
       "1750  [infomedia18, owned, restaurant, guide, burrp,...   \n",
       "1751  [online, restaurant, and, events, guide, has, ...   \n",
       "1752  [nowfloats, is, a, location, based, mobile, se...   \n",
       "1753  [updated, with, some, corrections, recently, m...   \n",
       "1754  [online, restaurants, and, events, guide, has,...   \n",
       "1755  [sandeep, das, has, joined, s, senior, managem...   \n",
       "1756  [speaking, with, medianama, vishal, anand, bur...   \n",
       "1757  [after, we, published, on, the, round, of, all...   \n",
       "1758  [e, commerce, marketplace, snapdeal, is, in, l...   \n",
       "1759  [online, fashion, store, myntra, has, acquired...   \n",
       "1760  [s, mobile, ads, mediation, and, optimization,...   \n",
       "1761  [online, ad, network, has, launched, a, real, ...   \n",
       "1762  [a, mobile, media, distribution, and, analytic...   \n",
       "1763  [a, mobile, advertising, platform, based, in, ...   \n",
       "1764  [mauj, people, infocomm, owned, mobile, applic...   \n",
       "1765  [ecommerce, giant, has, acquired, the, mobile,...   \n",
       "1766  [update, flipkart, has, confirmed, the, acquis...   \n",
       "1767                   [anurag, dod, tanuj, mendiratta]   \n",
       "1768  [after, recently, its, music, search, engine, ...   \n",
       "\n",
       "                                                  title  \n",
       "0     [why, has, the, trai, issued, another, net, ne...  \n",
       "1     [funding, roundup, wow, express, opinio, picki...  \n",
       "2     [what, mps, said, on, net, neutrality, in, the...  \n",
       "3     [rajeev, chandrasekhar, on, reddit, ama, trai,...  \n",
       "4     [opinio, secures, 7m, from, delhivery, sands, ...  \n",
       "5     [magicbricks, calls, out, 99acres, on, its, no...  \n",
       "6     [net, neutrality, misconceptions, and, misdire...  \n",
       "7     [twitter, offering, reliance, subscribers, fre...  \n",
       "8     [coai, s, net, neutrality, campaign, gets, 40,...  \n",
       "9     [rivigo, raises, 30m, from, saif, partners, ot...  \n",
       "10    [practo, co, founder, shashank, nd, on, expans...  \n",
       "11    [mobikwik, ceo, bipin, singh, s, reddit, ama, ...  \n",
       "12    [gsf, wheredowegonow, phanindra, sama, on, eso...  \n",
       "13    [why, kanwal, rekhi, didn, t, want, to, exit, ...  \n",
       "14    [parcelled, secures, 5m, from, delhivery, trac...  \n",
       "15    [how, indian, telecom, operators, defend, thei...  \n",
       "16    [net, neutrality, telcos, are, not, losing, mo...  \n",
       "17    [meena, k, ganesh, srikanth, iyer, launch, onl...  \n",
       "18    [jabong, myntra, yebhi, using, transaction, sm...  \n",
       "19    [e, commerce, roundup, amazon, jabong, flipkar...  \n",
       "20    [e, commerce, roundup, nature, s, basket, snap...  \n",
       "21    [vserv, partners, xl, to, enable, customer, ta...  \n",
       "22    [vserv, ropes, in, shailesh, varudkar, as, vp,...  \n",
       "23              [vserv, launches, appwrapper, platform]  \n",
       "24    [vserv, launches, wap, java, apps, ad, network...  \n",
       "25              [inmobi, debuts, native, ads, platform]  \n",
       "26    [industry, moves, omg, vserv, mindshare, port,...  \n",
       "27            [industry, moves, vserv, mobi, network18]  \n",
       "28    [inmobi, focus, back, on, india, plans, appoin...  \n",
       "29    [seventynine, launches, mobile, app, analytics...  \n",
       "...                                                 ...  \n",
       "1739  [tv18, net, losses, at, rs, 415m, rs, 45m, was...  \n",
       "1740  [web18, roundup, burrp, indrive, im, launch, u...  \n",
       "1741  [q1, 10, tv18, net, loss, soars, to, rs, 406, ...  \n",
       "1742  [industry, moves, freecharge, in, possible, wo...  \n",
       "1743  [updated, q409, results, infomedia18, qoq, net...  \n",
       "1744  [infomedia18, had, acquired, burrp, for, rs, 4...  \n",
       "1745  [round, up, loop, goes, to, tn, orissa, saavn,...  \n",
       "1746  [network18, net, loss, down, 74, setpro, rev, ...  \n",
       "1747  [zomato, accuses, burrp, of, copying, listings...  \n",
       "1748  [news, digest, just, dial, bharti, olive, tele...  \n",
       "1749  [app, round, up, firstpost, getit, burrp, cond...  \n",
       "1750  [burrp, launches, restaurant, discovery, tool,...  \n",
       "1751             [burrp, launches, iphone, app, review]  \n",
       "1752  [nowfloats, offers, location, based, contextua...  \n",
       "1753  [updated, indian, apps, for, windows, 8, cp, i...  \n",
       "1754  [burrp, launches, invite, only, loyalty, club,...  \n",
       "1755  [antfarm, plans, to, enter, fitness, classifie...  \n",
       "1756  [just, let, s, get, back, to, business, it, s,...  \n",
       "1757  [we, have, decided, not, to, take, any, legal,...  \n",
       "1758        [why, snapdeal, wants, to, buy, freecharge]  \n",
       "1759  [myntra, acquires, mobile, app, development, p...  \n",
       "1760  [guruji, com, s, adiquity, launches, ad, excha...  \n",
       "1761  [komli, launches, real, time, bidding, based, ...  \n",
       "1762  [seventynine, launches, mobile, app, analytics...  \n",
       "1763  [mobile, ad, network, adiquity, partners, with...  \n",
       "1764  [mobango, integrates, guruji, com, s, adiquity...  \n",
       "1765  [after, adiquity, flipkart, acquires, mobile, ...  \n",
       "1766  [updated, flipkart, buys, out, mobile, ad, fir...  \n",
       "1767  [ceos, of, acquired, cos, adiquity, and, appit...  \n",
       "1768  [guruji, com, launches, mobile, ads, optimizat...  \n",
       "\n",
       "[1769 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mn_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mn_data['tit_uni'] = mn_data['title'].apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mn_data = mn_data.ix[mn_data['tit_uni'].drop_duplicates().index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mn_data.reset_index(inplace=True)\n",
    "del mn_data['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del mn_data['tit_uni']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mn_data.to_pickle('mn_posts.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
